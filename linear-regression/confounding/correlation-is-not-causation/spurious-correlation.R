# Spurious correlation

library(tidyverse)
library(dslabs)

# The following comical example underscores that correlation 
# is not causation. It shows a very strong correlation 
# between divorce rates and margarine consumption.


plot_tile <- paste("Correlation =", 
                   round(with(divorce_margarine, 
                              cor(margarine_consumption_per_capita, divorce_rate_maine)),2))
data(divorce_margarine)
divorce_margarine %>% 
  ggplot(aes(margarine_consumption_per_capita, divorce_rate_maine)) + 
  geom_point(cex=3) + 
  geom_smooth(method = "lm") + 
  ggtitle(plot_tile) +
  xlab("Margarine Consumption per Capita (lbs)") + 
  ylab("Divorce rate in Maine (per 1000)")

# Does this mean that margarine causes divorces? Or do 
# divorces cause people to eat more margarine? Of course 
# the answer to both these questions is no. This is just 
# an example of what we call a spurious correlation.

# You can see many more absurd examples on the Spurious
# Correlations website.

# The cases presented in the spurious correlation site are 
# all instances of what is generally called data dredging, 
# data fishing, or data snooping. It’s basically a form 
# of what in the US they call cherry picking. An example 
# of data dredging would be if you look through many 
# results produced by a random process and pick the 
# one that shows a relationship that supports a 
# theory you want to defend.

# A Monte Carlo simulation can be used to show how data 
# dredging can result in finding high correlations
# among uncorrelated variables. We will save the
# results of our simulation into a tibble:

N = 25
g = 1000000
sim_data = tibble(group = rep(1:g, each=N), 
                   x = rnorm(N * g), 
                   y = rnorm(N * g))

# The first column denotes group. We created groups and 
# for each one we generated a pair of independent vectors,
# X and Y, with 25 observations each, stored in the second 
# and third columns. Because we constructed the simulation, 
# we know that X and Y are not correlated.
# Next, we compute the correlation between X and Y for 
# each group and look at the max:

res = as.data.frame(sim_data) %>%
  group_by(group) %>%
  summarize(correlation = cor(x, y)) %>%
  arrange(desc(correlation))

# We see a maximum correlation of ~0.7 and if you just plot
# the data from the group achieving this correlation, it 
# shows a convincing plot that X and Y are in fact correlated:

sim_data %>%
  filter(group == res$group[1]) %>%
  ggplot(aes(x, y)) +
  geom_point() +
  geom_smooth(method = "lm")

# Remember that the correlation summary is a random 
# variable. Here is the distribution generated by the 
# Monte Carlo simulation:

res %>% 
  ggplot(aes(x=correlation)) + 
  geom_histogram(binwidth = 0.1, color = "black")

# It’s just a mathematical fact that if we observe random 
# correlations that are expected to be 0, but have a 
# standard error of 0.204, the largest one will be close to 1.

# If we performed regression on this group and interpreted 
# the p-value, we would incorrectly claim this was a 
# statistically significant relation:

library(broom)
sim_data %>%
  filter(group == res$group[1]) %>%
  summarize(tidy(lm(y ~ x, data =.))) %>%
  filter(term == "x")

# This particular form of data dredging is referred to as
# p-hacking. P-hacking is a topic of much discussion because 
# it is a problem in scientific publications. Because 
# publishers tend to reward statistically significant 
# results over negative results, there is an incentive 
# to report significant results. In epidemiology and the 
# social sciences, for example, researchers may look for 
# associations between an adverse outcome and several 
# exposures and report only the one exposure that 
# resulted in a small p-value. Furthermore, they might 
# try fitting several different models to account for 
# confounding and pick the one that yields the smallest 
# p-value. In experimental disciplines, an experiment 
# might be repeated more than once, yet only the results
# of the one experiment with a small p-value reported. 
# This does not necessarily happen due to unethical 
# behavior, but rather as a result of statistical 
# ignorance or wishful thinking. In advanced 
# statistics courses, you can learn methods to adjust 
# for these multiple comparisons.
